{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2SeqAllenNLP-BERT.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulxuereb/ML/blob/master/Seq2SeqAllenNLP_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "fRhwNb-LG7jC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "http://www.realworldnlpbook.com/blog/building-seq2seq-machine-translation-models-using-allennlp.html"
      ]
    },
    {
      "metadata": {
        "id": "PDiQMwzoG4qZ",
        "colab_type": "code",
        "outputId": "d47bdc6b-6652-449d-a267-08e874612244",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3363
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install AllenNLP"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting AllenNLP\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/c8/10342a6068a8d156a5947e03c95525d559e71ad62de0f2585ab922e14533/allennlp-0.8.3-py3-none-any.whl (5.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.6MB 8.8MB/s \n",
            "\u001b[?25hCollecting pytorch-pretrained-bert>=0.6.0 (from AllenNLP)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/3c/d5fa084dd3a82ffc645aba78c417e6072ff48552e3301b1fa3bd711e03d4/pytorch_pretrained_bert-0.6.1-py3-none-any.whl (114kB)\n",
            "\u001b[K    100% |████████████████████████████████| 122kB 37.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from AllenNLP) (3.6.4)\n",
            "Collecting conllu==0.11 (from AllenNLP)\n",
            "  Downloading https://files.pythonhosted.org/packages/d4/2c/856344d9b69baf5b374c395b4286626181a80f0c2b2f704914d18a1cea47/conllu-0.11-py2.py3-none-any.whl\n",
            "Collecting awscli>=1.11.91 (from AllenNLP)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/97/ff852dd99ccf679fecba6ed43cd65a808d8ed1f74bbc9757c37dbab85e68/awscli-1.16.145-py2.py3-none-any.whl (1.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.5MB 25.6MB/s \n",
            "\u001b[?25hCollecting moto>=1.3.4 (from AllenNLP)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/35/f3dc85fa8fa2541b77849459363bb0d6e02bd44ba05afbd3ee3e035a6b14/moto-1.3.8-py2.py3-none-any.whl (580kB)\n",
            "\u001b[K    100% |████████████████████████████████| 583kB 31.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack<0.6.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from AllenNLP) (0.5.6)\n",
            "Collecting flask-cors>=3.0.7 (from AllenNLP)\n",
            "  Downloading https://files.pythonhosted.org/packages/65/cb/683f71ff8daa3aea0a5cbb276074de39f9ab66d3fbb8ad5efb5bb83e90d2/Flask_Cors-3.0.7-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from AllenNLP) (1.16.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from AllenNLP) (3.2.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from AllenNLP) (1.9.134)\n",
            "Requirement already satisfied: spacy<2.2,>=2.0 in /usr/local/lib/python3.6/dist-packages (from AllenNLP) (2.0.18)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.6/dist-packages (from AllenNLP) (2018.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from AllenNLP) (2.8.0)\n",
            "Collecting ftfy (from AllenNLP)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/86/df789c5834f15ae1ca53a8d4c1fc4788676c2e32112f6a786f2625d9c6e6/ftfy-5.5.1-py3-none-any.whl (43kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 28.9MB/s \n",
            "\u001b[?25hCollecting word2number>=1.1 (from AllenNLP)\n",
            "  Downloading https://files.pythonhosted.org/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip\n",
            "Collecting jsonnet>=0.10.0; sys_platform != \"win32\" (from AllenNLP)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/dc/3abd3971869a741d7acdba166d71d4f9366b6b53028dfd56f95de356af0f/jsonnet-0.12.1.tar.gz (240kB)\n",
            "\u001b[K    100% |████████████████████████████████| 245kB 35.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from AllenNLP) (1.0.1.post2)\n",
            "Collecting flaky (from AllenNLP)\n",
            "  Downloading https://files.pythonhosted.org/packages/02/42/cca66659a786567c8af98587d66d75e7d2b6e65662f8daab75db708ac35b/flaky-3.5.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from AllenNLP) (1.2.1)\n",
            "Collecting overrides (from AllenNLP)\n",
            "  Downloading https://files.pythonhosted.org/packages/de/55/3100c6d14c1ed177492fcf8f07c4a7d2d6c996c0a7fc6a9a0a41308e7eec/overrides-1.9.tar.gz\n",
            "Requirement already satisfied: sqlparse>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from AllenNLP) (0.3.0)\n",
            "Collecting numpydoc>=0.8.0 (from AllenNLP)\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/f3/7cfe4c616e4b9fe05540256cc9c6661c052c8a4cec2915732793b36e1843/numpydoc-0.9.1.tar.gz\n",
            "Requirement already satisfied: gevent>=1.3.6 in /usr/local/lib/python3.6/dist-packages (from AllenNLP) (1.4.0)\n",
            "Collecting unidecode (from AllenNLP)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/39/53096f9217b057cb049fe872b7fc7ce799a1a89b76cf917d9639e7a558b5/Unidecode-1.0.23-py2.py3-none-any.whl (237kB)\n",
            "\u001b[K    100% |████████████████████████████████| 245kB 34.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from AllenNLP) (3.0.3)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from AllenNLP) (0.5.3)\n",
            "Collecting tensorboardX>=1.2 (from AllenNLP)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/76/89dd44458eb976347e5a6e75eb79fecf8facd46c1ce259bad54e0044ea35/tensorboardX-1.6-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 41.6MB/s \n",
            "\u001b[?25hCollecting parsimonious>=0.8.0 (from AllenNLP)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/fc/067a3f89869a41009e1a7cdfb14725f8ddd246f30f63c645e8ef8a1c56f4/parsimonious-0.8.1.tar.gz (45kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 26.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from AllenNLP) (2.21.0)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from AllenNLP) (4.28.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from AllenNLP) (0.20.3)\n",
            "Requirement already satisfied: flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from AllenNLP) (1.0.2)\n",
            "Collecting responses>=0.7 (from AllenNLP)\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/5a/b887e89925f1de7890ef298a74438371ed4ed29b33def9e6d02dc6036fd8/responses-0.10.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.0->AllenNLP) (2018.1.10)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->AllenNLP) (7.0.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->AllenNLP) (1.12.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->AllenNLP) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->AllenNLP) (19.1.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->AllenNLP) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->AllenNLP) (40.9.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->AllenNLP) (1.8.0)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->AllenNLP) (0.2.0)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->AllenNLP) (0.14)\n",
            "Collecting botocore==1.12.135 (from awscli>=1.11.91->AllenNLP)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/36/08db4978d59d75750ef6da9835150b901c6fb96f6d5f30d8c50eb424ed4e/botocore-1.12.135-py2.py3-none-any.whl (5.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.4MB 10.0MB/s \n",
            "\u001b[?25hCollecting colorama<=0.3.9,>=0.2.5 (from awscli>=1.11.91->AllenNLP)\n",
            "  Downloading https://files.pythonhosted.org/packages/db/c8/7dcf9dbcb22429512708fe3a547f8b6101c0d02137acbd892505aee57adf/colorama-0.3.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML<=3.13,>=3.10 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->AllenNLP) (3.13)\n",
            "Collecting rsa<=3.5.0,>=3.1.2 (from awscli>=1.11.91->AllenNLP)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/ae/baedc9cb175552e95f3395c43055a6a5e125ae4d48a1d7a924baca83e92e/rsa-3.4.2-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 29.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto>=2.36.0 in /usr/local/lib/python3.6/dist-packages (from moto>=1.3.4->AllenNLP) (2.49.0)\n",
            "Requirement already satisfied: werkzeug in /usr/local/lib/python3.6/dist-packages (from moto>=1.3.4->AllenNLP) (0.15.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from moto>=1.3.4->AllenNLP) (2.8)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from moto>=1.3.4->AllenNLP) (2.5.3)\n",
            "Collecting cfn-lint (from moto>=1.3.4->AllenNLP)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/82/f3c539fb6db5776b49138a8d9212a99313172d701b11e05824d224590483/cfn_lint-0.19.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.1MB 19.7MB/s \n",
            "\u001b[?25hCollecting jsondiff==1.1.2 (from moto>=1.3.4->AllenNLP)\n",
            "  Downloading https://files.pythonhosted.org/packages/33/0c/ddb17571e061c655871ccbf76cdada55a31569327d21517de779d4887241/jsondiff-1.1.2.tar.gz\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from moto>=1.3.4->AllenNLP) (2.10.1)\n",
            "Collecting docker>=2.5.1 (from moto>=1.3.4->AllenNLP)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/68/c3afca1a5aa8d2997ec3b8ee822a4d752cf85907b321f07ea86888545152/docker-3.7.2-py2.py3-none-any.whl (134kB)\n",
            "\u001b[K    100% |████████████████████████████████| 143kB 28.5MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.3.0 (from moto>=1.3.4->AllenNLP)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/12/b0409a94dad366d98a8eee2a77678c7a73aafd8c0e4b835abea634ea3896/cryptography-2.6.1-cp34-abi3-manylinux1_x86_64.whl (2.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.3MB 18.1MB/s \n",
            "\u001b[?25hCollecting xmltodict (from moto>=1.3.4->AllenNLP)\n",
            "  Downloading https://files.pythonhosted.org/packages/28/fd/30d5c1d3ac29ce229f6bdc40bbc20b28f716e8b363140c26eff19122d8a5/xmltodict-0.12.0-py2.py3-none-any.whl\n",
            "Collecting python-jose<4.0.0 (from moto>=1.3.4->AllenNLP)\n",
            "  Downloading https://files.pythonhosted.org/packages/96/da/c0dcc5e7a98a53440b8db3cf9771345fa696754f79e8734ea59123f7d734/python_jose-3.0.1-py2.py3-none-any.whl\n",
            "Collecting aws-xray-sdk!=0.96,>=0.93 (from moto>=1.3.4->AllenNLP)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/f2/79f7918f4ddeec525742ddd4607abe4a82a29a6bc4c7e297995f59a18965/aws_xray_sdk-2.4.2-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K    100% |████████████████████████████████| 92kB 37.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: mock in /usr/local/lib/python3.6/dist-packages (from moto>=1.3.4->AllenNLP) (2.0.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->AllenNLP) (0.9.4)\n",
            "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0->AllenNLP) (0.2.9)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0->AllenNLP) (2.0.1)\n",
            "Requirement already satisfied: thinc<6.13.0,>=6.12.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0->AllenNLP) (6.12.1)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0->AllenNLP) (0.9.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0->AllenNLP) (2.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0->AllenNLP) (1.0.2)\n",
            "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0->AllenNLP) (1.35)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->AllenNLP) (0.1.7)\n",
            "Requirement already satisfied: sphinx>=1.6.5 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.8.0->AllenNLP) (1.8.5)\n",
            "Requirement already satisfied: greenlet>=0.4.14; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.6/dist-packages (from gevent>=1.3.6->AllenNLP) (0.4.15)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->AllenNLP) (1.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->AllenNLP) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->AllenNLP) (2.4.0)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->AllenNLP) (3.7.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->AllenNLP) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->AllenNLP) (1.24.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->AllenNLP) (3.0.4)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->AllenNLP) (7.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->AllenNLP) (1.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<=3.5.0,>=3.1.2->awscli>=1.11.91->AllenNLP) (0.4.5)\n",
            "Collecting aws-sam-translator>=1.10.0 (from cfn-lint->moto>=1.3.4->AllenNLP)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/6c/9ae54e75977fe6284723af19b4c5ef8ef48fac2263d5808f2d091f5adcf6/aws-sam-translator-1.10.0.tar.gz (92kB)\n",
            "\u001b[K    100% |████████████████████████████████| 92kB 36.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema~=2.6 in /usr/local/lib/python3.6/dist-packages (from cfn-lint->moto>=1.3.4->AllenNLP) (2.6.0)\n",
            "Collecting jsonpatch (from cfn-lint->moto>=1.3.4->AllenNLP)\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/e6/d50d526ae2218b765ddbdb2dda14d65e19f501ce07410b375bc43ad20b7a/jsonpatch-1.23-py2.py3-none-any.whl\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->moto>=1.3.4->AllenNLP) (1.1.1)\n",
            "Collecting docker-pycreds>=0.4.0 (from docker>=2.5.1->moto>=1.3.4->AllenNLP)\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Collecting websocket-client>=0.32.0 (from docker>=2.5.1->moto>=1.3.4->AllenNLP)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K    100% |████████████████████████████████| 204kB 38.0MB/s \n",
            "\u001b[?25hCollecting asn1crypto>=0.21.0 (from cryptography>=2.3.0->moto>=1.3.4->AllenNLP)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/cd/35485615f45f30a510576f1a56d1e0a7ad7bd8ab5ed7cdc600ef7cd06222/asn1crypto-0.24.0-py2.py3-none-any.whl (101kB)\n",
            "\u001b[K    100% |████████████████████████████████| 102kB 39.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.3.0->moto>=1.3.4->AllenNLP) (1.12.3)\n",
            "Collecting ecdsa<1.0 (from python-jose<4.0.0->moto>=1.3.4->AllenNLP)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/a8/8aa68e70959e1287da9154e5164bb8bd5dd7025e41ae54e8d177b8d165c9/ecdsa-0.13.2-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 30.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: future<1.0 in /usr/local/lib/python3.6/dist-packages (from python-jose<4.0.0->moto>=1.3.4->AllenNLP) (0.16.0)\n",
            "Collecting jsonpickle (from aws-xray-sdk!=0.96,>=0.93->moto>=1.3.4->AllenNLP)\n",
            "  Downloading https://files.pythonhosted.org/packages/dc/12/8c44eabb501e2bc0aec0dd152b328074d98a50968d3a02be28f6037f0c6a/jsonpickle-1.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from aws-xray-sdk!=0.96,>=0.93->moto>=1.3.4->AllenNLP) (1.10.11)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock->moto>=1.3.4->AllenNLP) (5.1.3)\n",
            "Requirement already satisfied: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy<2.2,>=2.0->AllenNLP) (0.4.3.2)\n",
            "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy<2.2,>=2.0->AllenNLP) (0.9.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->AllenNLP) (1.1.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->AllenNLP) (2.6.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->AllenNLP) (1.2.1)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->AllenNLP) (2.1.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->AllenNLP) (19.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->AllenNLP) (1.1.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->AllenNLP) (0.7.12)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch->cfn-lint->moto>=1.3.4->AllenNLP)\n",
            "  Downloading https://files.pythonhosted.org/packages/18/b0/a80d29577c08eea401659254dfaed87f1af45272899e1812d7e01b679bc5/jsonpointer-2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.3.0->moto>=1.3.4->AllenNLP) (2.19)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy<2.2,>=2.0->AllenNLP) (0.9.0)\n",
            "Building wheels for collected packages: word2number, jsonnet, overrides, numpydoc, parsimonious, jsondiff, aws-sam-translator\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/46/2f/53/5f5c1d275492f2fce1cdab9a9bb12d49286dead829a4078e0e\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/f0/47/51/a178b15274ed0db775a1ae9c799ce31e511609c3ab75a7dec5\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/8d/52/86/e5a83b1797e7d263b458d2334edd2704c78508b3eea9323718\n",
            "  Building wheel for numpydoc (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/51/30/d1/92a39ba40f21cb70e53f8af96eb98f002a781843c065406500\n",
            "  Building wheel for parsimonious (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/b7/8d/e7/a0e74217da5caeb3c1c7689639b6d28ddbf9985b840bc96a9a\n",
            "  Building wheel for jsondiff (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/46/5f/86/11c6b72b064888e80b98bfcbcdaf2a83517a8cf8f2bb2a3227\n",
            "  Building wheel for aws-sam-translator (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/2d/2e/08/948f0efb297073d0b2b752c5f6437b9f115d554fa72f499eb5\n",
            "Successfully built word2number jsonnet overrides numpydoc parsimonious jsondiff aws-sam-translator\n",
            "Installing collected packages: pytorch-pretrained-bert, conllu, botocore, colorama, rsa, awscli, responses, aws-sam-translator, jsonpointer, jsonpatch, cfn-lint, jsondiff, docker-pycreds, websocket-client, docker, asn1crypto, cryptography, xmltodict, ecdsa, python-jose, jsonpickle, aws-xray-sdk, moto, flask-cors, ftfy, word2number, jsonnet, flaky, overrides, numpydoc, unidecode, tensorboardX, parsimonious, AllenNLP\n",
            "  Found existing installation: botocore 1.12.134\n",
            "    Uninstalling botocore-1.12.134:\n",
            "      Successfully uninstalled botocore-1.12.134\n",
            "  Found existing installation: rsa 4.0\n",
            "    Uninstalling rsa-4.0:\n",
            "      Successfully uninstalled rsa-4.0\n",
            "Successfully installed AllenNLP-0.8.3 asn1crypto-0.24.0 aws-sam-translator-1.10.0 aws-xray-sdk-2.4.2 awscli-1.16.145 botocore-1.12.135 cfn-lint-0.19.1 colorama-0.3.9 conllu-0.11 cryptography-2.6.1 docker-3.7.2 docker-pycreds-0.4.0 ecdsa-0.13.2 flaky-3.5.3 flask-cors-3.0.7 ftfy-5.5.1 jsondiff-1.1.2 jsonnet-0.12.1 jsonpatch-1.23 jsonpickle-1.1 jsonpointer-2.0 moto-1.3.8 numpydoc-0.9.1 overrides-1.9 parsimonious-0.8.1 python-jose-3.0.1 pytorch-pretrained-bert-0.6.1 responses-0.10.6 rsa-3.4.2 tensorboardX-1.6 unidecode-1.0.23 websocket-client-0.56.0 word2number-1.1 xmltodict-0.12.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "rsa"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "xuF4XVB4HEyJ",
        "colab_type": "code",
        "outputId": "9bf9c1c5-4ba7-47a6-ad5f-f5f27281e6a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "    \n",
        "import itertools\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from allennlp.data.dataset_readers.seq2seq import Seq2SeqDatasetReader\n",
        "from allennlp.data.iterators import BucketIterator\n",
        "from allennlp.data.token_indexers import SingleIdTokenIndexer\n",
        "from allennlp.data.tokenizers.character_tokenizer import CharacterTokenizer\n",
        "from allennlp.data.tokenizers.word_tokenizer import WordTokenizer\n",
        "from allennlp.data.vocabulary import Vocabulary\n",
        "from allennlp.nn.activations import Activation\n",
        "from allennlp.models.encoder_decoders.simple_seq2seq import SimpleSeq2Seq\n",
        "from allennlp.modules.attention import LinearAttention, BilinearAttention, DotProductAttention\n",
        "from allennlp.modules.seq2seq_encoders import PytorchSeq2SeqWrapper, StackedSelfAttentionEncoder\n",
        "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
        "from allennlp.modules.token_embedders import Embedding\n",
        "from allennlp.predictors import SimpleSeq2SeqPredictor\n",
        "from allennlp.training.trainer import Trainer\n",
        "from allennlp.modules.token_embedders.bert_token_embedder import PretrainedBertEmbedder"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kcmDhjkTJ1DH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Setup data files"
      ]
    },
    {
      "metadata": {
        "id": "CHYbBnnRHhuO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3RpzW1tYHq_Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c0964c15-64ff-4294-f426-3ba9ead95cc5"
      },
      "cell_type": "code",
      "source": [
        "%cd data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'data'\n",
            "/content/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8PSWXWwOHtMX",
        "colab_type": "code",
        "outputId": "02d95d10-8582-4d02-ebae-59af1328cf0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://downloads.tatoeba.org/exports/sentences.tar.bz2"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-25 09:48:58--  http://downloads.tatoeba.org/exports/sentences.tar.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.tatoeba.org/exports/sentences.tar.bz2 [following]\n",
            "--2019-04-25 09:48:58--  https://downloads.tatoeba.org/exports/sentences.tar.bz2\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 118227705 (113M) [application/octet-stream]\n",
            "Saving to: ‘sentences.tar.bz2’\n",
            "\n",
            "sentences.tar.bz2   100%[===================>] 112.75M  19.2MB/s    in 6.9s    \n",
            "\n",
            "2019-04-25 09:49:06 (16.4 MB/s) - ‘sentences.tar.bz2’ saved [118227705/118227705]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eu_n_GYdIwrl",
        "colab_type": "code",
        "outputId": "ad1a6369-5fb9-4915-eff9-aa4f73d8d804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://downloads.tatoeba.org/exports/links.tar.bz2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2019-04-25 09:49:09--  https://downloads.tatoeba.org/exports/links.tar.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 80800484 (77M) [application/octet-stream]\n",
            "Saving to: ‘links.tar.bz2’\n",
            "\n",
            "links.tar.bz2       100%[===================>]  77.06M  19.3MB/s    in 4.8s    \n",
            "\n",
            "2019-04-25 09:49:15 (16.1 MB/s) - ‘links.tar.bz2’ saved [80800484/80800484]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ay7JODVwI23j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RJGasjmQUDE-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3cec358-24dd-44f6-c706-daa7101cff0e"
      },
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0ch9LiTjI5QY",
        "colab_type": "code",
        "outputId": "f3c8f2b1-a714-4f5f-e667-917857efe01b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!tar -xvf sentences.tar.bz2"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentences.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xkP0i7BFJGZa",
        "colab_type": "code",
        "outputId": "588946e9-b17a-4fef-eee5-221989ff20ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!tar -xvf links.tar.bz2"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "links.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i07O2YhxJbS2",
        "colab_type": "code",
        "outputId": "73160f0e-fd66-4177-be64-a10bac96bc9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mhagiwara/realworldnlp/master/examples/mt/create_bitext.py"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-25 09:49:54--  https://raw.githubusercontent.com/mhagiwara/realworldnlp/master/examples/mt/create_bitext.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4870 (4.8K) [text/plain]\n",
            "Saving to: ‘create_bitext.py’\n",
            "\n",
            "\rcreate_bitext.py      0%[                    ]       0  --.-KB/s               \rcreate_bitext.py    100%[===================>]   4.76K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-04-25 09:49:54 (88.2 MB/s) - ‘create_bitext.py’ saved [4870/4870]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QvhG-4cxJhJt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python create_bitext.py eng_cmn sentences.csv links.csv \\\n",
        "    | cut -f3,6 > tatoeba.eng_cmn.tsv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QUYdcBdYKVYi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cat tatoeba.eng_cmn.tsv | awk 'NR%10==1' > tatoeba.eng_cmn.test.tsv\n",
        "!cat tatoeba.eng_cmn.tsv | awk 'NR%10==2' > tatoeba.eng_cmn.dev.tsv\n",
        "!cat tatoeba.eng_cmn.tsv | awk 'NR%10!=1&&NR%10!=2' > tatoeba.eng_cmn.train.tsv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BfwV5YhsJ38P",
        "colab_type": "code",
        "outputId": "f4ecd29e-ac15-4182-c40d-69a61e98acc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "create_bitext.py  sample_data\t\t   tatoeba.eng_cmn.test.tsv\n",
            "data\t\t  sentences.csv\t\t   tatoeba.eng_cmn.train.tsv\n",
            "links.csv\t  sentences.tar.bz2\t   tatoeba.eng_cmn.tsv\n",
            "links.tar.bz2\t  tatoeba.eng_cmn.dev.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1blHnXUR57C0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "a3eda0b6-c118-4737-edb2-9efddd708a2f"
      },
      "cell_type": "code",
      "source": [
        "!head tatoeba.eng_cmn.train.tsv"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Today is June 18th and it is Muiriel's birthday!\t今天是６月１８号，也是Muiriel的生日！\n",
            "Muiriel is 20 now.\tMuiriel现在20岁了。\n",
            "The password is \"Muiriel\".\t密码是\"Muiriel\"。\n",
            "The password is \"Muiriel\".\t密碼是「Muiriel」。\n",
            "I will be back soon.\t我很快就會回來。\n",
            "I'm at a loss for words.\t我不知道應該說什麼才好。\n",
            "This is never going to end.\t這個永遠完不了了。\n",
            "This is never going to end.\t这将永远继续下去。\n",
            "That was an evil bunny.\t那是一隻有惡意的兔子。\n",
            "I was in the mountains.\t我以前在山里。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "guj13h_970VP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Grab the Microsoft chat files"
      ]
    },
    {
      "metadata": {
        "id": "RRoGGRQX6T46",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "0cb0e5de-4b46-4816-ade5-8516a620feef"
      },
      "cell_type": "code",
      "source": [
        "!wget https://qnamakerstore.blob.core.windows.net/qnamakerdata/editorial/qna_chitchat_the_professional.tsv"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-25 09:52:48--  https://qnamakerstore.blob.core.windows.net/qnamakerdata/editorial/qna_chitchat_the_professional.tsv\n",
            "Resolving qnamakerstore.blob.core.windows.net (qnamakerstore.blob.core.windows.net)... 13.88.144.240\n",
            "Connecting to qnamakerstore.blob.core.windows.net (qnamakerstore.blob.core.windows.net)|13.88.144.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 62473 (61K) [text/tab-separated-values]\n",
            "Saving to: ‘qna_chitchat_the_professional.tsv’\n",
            "\n",
            "\r          qna_chitc   0%[                    ]       0  --.-KB/s               \rqna_chitchat_the_pr 100%[===================>]  61.01K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-04-25 09:52:48 (1.35 MB/s) - ‘qna_chitchat_the_professional.tsv’ saved [62473/62473]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y52DdvOc6X0Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"qna_chitchat_the_professional.tsv\",sep='\\t')\n",
        "#df.drop(['Source', 'Metadata'])\n",
        "#df1 = df[['user1','user2']]\n",
        "#df1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eE3maeyg60cW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df1 = df[['Question','Answer']]\n",
        "df1\n",
        "df1.to_csv('chat.tsv', sep = '\\t', header=False, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8mF-5H_v7ZCc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "44d9c2d0-ef60-469f-9e97-47e1b6b94e86"
      },
      "cell_type": "code",
      "source": [
        "!head chat.tsv"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What's your age?\tAge doesn't really apply to me.\n",
            "Are you young?\tAge doesn't really apply to me.\n",
            "When were you born?\tAge doesn't really apply to me.\n",
            "What age are you?\tAge doesn't really apply to me.\n",
            "Are you old?\tAge doesn't really apply to me.\n",
            "How old are you?\tAge doesn't really apply to me.\n",
            "How long ago were you born?\tAge doesn't really apply to me.\n",
            "Ask me anything\tI'm better at answering questions.\n",
            "Ask me a question\tI'm better at answering questions.\n",
            "Can you ask me a question?\tI'm better at answering questions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LqeAmIF5758A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cat chat.tsv | awk 'NR%10==1' > chat.eng_cmn.test.tsv\n",
        "!cat chat.tsv | awk 'NR%10==2' > chat.eng_cmn.dev.tsv\n",
        "!cat chat.tsv | awk 'NR%10!=1&&NR%10!=2' > chat.eng_cmn.train.tsv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dr9fgbX08FNO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "b154ea26-17f9-453b-a1ba-9b49b4d727d9"
      },
      "cell_type": "code",
      "source": [
        "!ls\n",
        "#!head chat.eng_cmn.dev.tsv"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Are you young?\tAge doesn't really apply to me.\n",
            "What do you want to know about me?\tI'm better at answering questions.\n",
            "You bore me\tI aim for efficiency.\n",
            "Why are you so boring?\tI aim for efficiency.\n",
            "Cook me something\tThat's not something I can do.\n",
            "What can you do?\tI'm here to answer your questions and help out.\n",
            "Which people made you?\tPeople created me.\n",
            "Do you have a family?\tI don't have family.\n",
            "Are you a man?\tThat's a biological concept that doesn't apply to me.\n",
            "What's your gender?\tThat's a biological concept that doesn't apply to me.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FlehUdQWKA_p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Build the model"
      ]
    },
    {
      "metadata": {
        "id": "qT3MJIzGUcUG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d473a6b5-10f3-4b7a-8351-3ca969989d96"
      },
      "cell_type": "code",
      "source": [
        " bert_embedder = PretrainedBertEmbedder(\n",
        "        pretrained_model=\"bert-base-uncased\",\n",
        "        top_layer_only=True)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:11<00:00, 35359038.76B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "4SSeTCqKHOch",
        "colab_type": "code",
        "outputId": "792b2be3-b87f-4e5a-884d-9edb584fca10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "EN_EMBEDDING_DIM = 256\n",
        "ZH_EMBEDDING_DIM = 256\n",
        "HIDDEN_DIM = 256\n",
        "CUDA_DEVICE = 0\n",
        "\n",
        "\n",
        "reader = Seq2SeqDatasetReader(\n",
        "        source_tokenizer=WordTokenizer(),\n",
        "        target_tokenizer=CharacterTokenizer(),\n",
        "        source_token_indexers={'tokens': SingleIdTokenIndexer()},\n",
        "        target_token_indexers={'tokens': SingleIdTokenIndexer(namespace='target_tokens')})\n",
        "train_dataset = reader.read('chat.eng_cmn.train.tsv')\n",
        "validation_dataset = reader.read('chat.eng_cmn.dev.tsv')\n",
        "\n",
        "vocab = Vocabulary.from_instances(train_dataset + validation_dataset,\n",
        "                                  min_count={'tokens': 3, 'target_tokens': 3})\n",
        "\n",
        "in_embedding = BasicTextFieldEmbedder({\"tokens\": bert_embedder},\n",
        "                                          allow_unmatched_keys=True)\n",
        "BERT_DIM = in_embedding.get_output_dim()\n",
        "\n",
        "\n",
        "encoder = PytorchSeq2SeqWrapper(torch.nn.LSTM(BERT_DIM,\n",
        "                                              HIDDEN_DIM,\n",
        "                                              batch_first=True))\n",
        "\n",
        "attention = BilinearAttention(HIDDEN_DIM, HIDDEN_DIM)\n",
        "max_decoding_steps = 250\n",
        "model = SimpleSeq2Seq(vocab, in_embedding, encoder, max_decoding_steps,\n",
        "                      target_embedding_dim=BERT_DIM,\n",
        "                      target_namespace=\"target_tokens\",\n",
        "                      attention=attention, beam_size=8)\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "iterator = BucketIterator(batch_size=32, sorting_keys=[(\"source_tokens\", \"num_tokens\")])\n",
        "\n",
        "iterator.index_with(vocab)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "525it [00:00, 10653.58it/s]\n",
            "66it [00:00, 7146.06it/s]\n",
            "100%|██████████| 591/591 [00:00<00:00, 33350.38it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "GiY0e3FLVwQb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#skip this\n",
        "en_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),\n",
        "                         embedding_dim=EN_EMBEDDING_DIM)\n",
        "# encoder = PytorchSeq2SeqWrapper(\n",
        "#     torch.nn.LSTM(EN_EMBEDDING_DIM, HIDDEN_DIM, batch_first=True))\n",
        "encoder = StackedSelfAttentionEncoder(input_dim=EN_EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, projection_dim=128, feedforward_hidden_dim=128, num_layers=1, num_attention_heads=8)\n",
        "\n",
        "source_embedder = BasicTextFieldEmbedder({\"tokens\": en_embedding})\n",
        "\n",
        "\n",
        "\n",
        "# attention = LinearAttention(HIDDEN_DIM, HIDDEN_DIM, activation=Activation.by_name('tanh')())\n",
        "# attention = BilinearAttention(HIDDEN_DIM, HIDDEN_DIM)\n",
        "attention = DotProductAttention()\n",
        "\n",
        "max_decoding_steps = 20   # TODO: make this variable\n",
        "model = SimpleSeq2Seq(vocab, source_embedder, encoder, max_decoding_steps,\n",
        "                      target_embedding_dim=ZH_EMBEDDING_DIM,\n",
        "                      target_namespace='target_tokens',\n",
        "                      attention=attention,\n",
        "                      beam_size=8,\n",
        "                      use_bleu=True)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "iterator = BucketIterator(batch_size=32, sorting_keys=[(\"source_tokens\", \"num_tokens\")])\n",
        "\n",
        "iterator.index_with(vocab)\n",
        "#end skip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b6PMYUmrWQSV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "UoN9KsCrHTQs",
        "colab_type": "code",
        "outputId": "8c3c12ec-2129-471f-bed6-624dac03e514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3202
        }
      },
      "cell_type": "code",
      "source": [
        "CUDA_DEVICE = 0\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    cuda_device = 0\n",
        "    model = model.cuda(cuda_device)\n",
        "else:\n",
        "    cuda_device = -1\n",
        "    \n",
        "\n",
        "trainer = Trainer(model=model,\n",
        "                      optimizer=optimizer,\n",
        "                      iterator=iterator,\n",
        "                      train_dataset=train_dataset,\n",
        "                      validation_dataset=validation_dataset,\n",
        "                      num_epochs=1,\n",
        "                      cuda_device=CUDA_DEVICE)\n",
        "\n",
        "for i in range(50):\n",
        "    print('Epoch: {}'.format(i))\n",
        "    metrics = trainer.train()\n",
        "\n",
        "    predictor = SimpleSeq2SeqPredictor(model, reader)\n",
        "\n",
        "    #do predictions on last epoch\n",
        "    if i >= 49:\n",
        "      for instance in itertools.islice(validation_dataset, 10):\n",
        "          print('SOURCE:', instance.fields['source_tokens'].tokens)\n",
        "          print('GOLD:', instance.fields['target_tokens'].tokens)\n",
        "          print('PRED:', predictor.predict_instance(instance)['predicted_tokens'])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n",
            "  0%|          | 0/17 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2613 ||: 100%|██████████| 17/17 [00:01<00:00, 10.87it/s]\n",
            "BLEU: 0.0008, loss: 0.2812 ||: 100%|██████████| 3/3 [00:00<00:00,  6.64it/s]\n",
            "  0%|          | 0/17 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2527 ||: 100%|██████████| 17/17 [00:01<00:00, 10.78it/s]\n",
            "BLEU: 0.0090, loss: 0.2662 ||: 100%|██████████| 3/3 [00:00<00:00,  6.10it/s]\n",
            "loss: 0.2395 ||:   6%|▌         | 1/17 [00:00<00:01,  9.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2490 ||: 100%|██████████| 17/17 [00:01<00:00, 11.63it/s]\n",
            "BLEU: 0.0027, loss: 0.2701 ||: 100%|██████████| 3/3 [00:00<00:00,  5.89it/s]\n",
            "loss: 0.2382 ||:   6%|▌         | 1/17 [00:00<00:01,  9.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2455 ||: 100%|██████████| 17/17 [00:01<00:00, 11.14it/s]\n",
            "BLEU: 0.0058, loss: 0.2540 ||: 100%|██████████| 3/3 [00:00<00:00,  6.65it/s]\n",
            "loss: 0.2260 ||:   6%|▌         | 1/17 [00:00<00:01,  9.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2415 ||: 100%|██████████| 17/17 [00:01<00:00, 11.10it/s]\n",
            "BLEU: 0.0198, loss: 0.2596 ||: 100%|██████████| 3/3 [00:00<00:00,  5.99it/s]\n",
            "loss: 0.2074 ||:   6%|▌         | 1/17 [00:00<00:01,  9.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2406 ||: 100%|██████████| 17/17 [00:01<00:00, 11.17it/s]\n",
            "BLEU: 0.0689, loss: 0.2580 ||: 100%|██████████| 3/3 [00:00<00:00,  6.38it/s]\n",
            "  0%|          | 0/17 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2365 ||: 100%|██████████| 17/17 [00:01<00:00, 11.54it/s]\n",
            "BLEU: 0.0038, loss: 0.2814 ||: 100%|██████████| 3/3 [00:00<00:00,  6.26it/s]\n",
            "  0%|          | 0/17 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2381 ||: 100%|██████████| 17/17 [00:01<00:00, 11.92it/s]\n",
            "BLEU: 0.0024, loss: 0.3190 ||: 100%|██████████| 3/3 [00:00<00:00,  5.48it/s]\n",
            "  0%|          | 0/17 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2373 ||: 100%|██████████| 17/17 [00:01<00:00, 11.36it/s]\n",
            "BLEU: 0.1074, loss: 0.2488 ||: 100%|██████████| 3/3 [00:00<00:00,  5.88it/s]\n",
            "loss: 0.2517 ||:   6%|▌         | 1/17 [00:00<00:01,  8.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2349 ||: 100%|██████████| 17/17 [00:01<00:00, 11.50it/s]\n",
            "BLEU: 0.0025, loss: 0.3001 ||: 100%|██████████| 3/3 [00:00<00:00,  6.02it/s]\n",
            "loss: 0.2666 ||:   6%|▌         | 1/17 [00:00<00:01,  9.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2313 ||: 100%|██████████| 17/17 [00:01<00:00, 11.59it/s]\n",
            "BLEU: 0.0041, loss: 0.2931 ||: 100%|██████████| 3/3 [00:00<00:00,  6.61it/s]\n",
            "  0%|          | 0/17 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2302 ||: 100%|██████████| 17/17 [00:01<00:00, 11.51it/s]\n",
            "BLEU: 0.0316, loss: 0.2414 ||: 100%|██████████| 3/3 [00:00<00:00,  6.10it/s]\n",
            "loss: 0.1935 ||:   6%|▌         | 1/17 [00:00<00:01,  9.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2314 ||: 100%|██████████| 17/17 [00:01<00:00, 11.19it/s]\n",
            "BLEU: 0.0005, loss: 0.2914 ||: 100%|██████████| 3/3 [00:00<00:00,  6.58it/s]\n",
            "loss: 0.1967 ||:   6%|▌         | 1/17 [00:00<00:01,  8.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2305 ||: 100%|██████████| 17/17 [00:01<00:00, 11.36it/s]\n",
            "BLEU: 0.0041, loss: 0.2884 ||: 100%|██████████| 3/3 [00:00<00:00,  5.55it/s]\n",
            "  0%|          | 0/17 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2286 ||: 100%|██████████| 17/17 [00:01<00:00, 11.57it/s]\n",
            "BLEU: 0.0036, loss: 0.2649 ||: 100%|██████████| 3/3 [00:00<00:00,  6.05it/s]\n",
            "loss: 0.2242 ||:   6%|▌         | 1/17 [00:00<00:01,  8.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2225 ||: 100%|██████████| 17/17 [00:01<00:00, 11.59it/s]\n",
            "BLEU: 0.0005, loss: 0.2799 ||: 100%|██████████| 3/3 [00:00<00:00,  5.92it/s]\n",
            "loss: 0.2282 ||:   6%|▌         | 1/17 [00:00<00:01,  9.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2235 ||: 100%|██████████| 17/17 [00:01<00:00, 11.18it/s]\n",
            "BLEU: 0.0043, loss: 0.2409 ||: 100%|██████████| 3/3 [00:00<00:00,  6.07it/s]\n",
            "loss: 0.2629 ||:   6%|▌         | 1/17 [00:00<00:01,  9.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2302 ||: 100%|██████████| 17/17 [00:01<00:00, 11.05it/s]\n",
            "BLEU: 0.0028, loss: 0.2977 ||: 100%|██████████| 3/3 [00:00<00:00,  5.59it/s]\n",
            "loss: 0.1973 ||:   6%|▌         | 1/17 [00:00<00:01,  8.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2304 ||: 100%|██████████| 17/17 [00:01<00:00, 11.43it/s]\n",
            "BLEU: 0.0156, loss: 0.2519 ||: 100%|██████████| 3/3 [00:00<00:00,  6.39it/s]\n",
            "  0%|          | 0/17 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.3985 ||: 100%|██████████| 17/17 [00:01<00:00, 11.27it/s]\n",
            "BLEU: 0.0004, loss: 0.4509 ||: 100%|██████████| 3/3 [00:00<00:00,  6.01it/s]\n",
            "loss: 0.3981 ||:   6%|▌         | 1/17 [00:00<00:01,  9.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.3435 ||: 100%|██████████| 17/17 [00:01<00:00, 10.92it/s]\n",
            "BLEU: 0.0003, loss: 0.3575 ||: 100%|██████████| 3/3 [00:00<00:00,  5.04it/s]\n",
            "  0%|          | 0/17 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2764 ||: 100%|██████████| 17/17 [00:01<00:00, 10.28it/s]\n",
            "BLEU: 0.0016, loss: 0.2710 ||: 100%|██████████| 3/3 [00:00<00:00,  5.40it/s]\n",
            "  0%|          | 0/17 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2523 ||: 100%|██████████| 17/17 [00:01<00:00, 10.24it/s]\n",
            "BLEU: 0.0001, loss: 0.2934 ||: 100%|██████████| 3/3 [00:00<00:00,  5.41it/s]\n",
            "  0%|          | 0/17 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2398 ||: 100%|██████████| 17/17 [00:01<00:00, 10.89it/s]\n",
            "BLEU: 0.0034, loss: 0.2796 ||: 100%|██████████| 3/3 [00:00<00:00,  5.83it/s]\n",
            "loss: 0.2637 ||:   6%|▌         | 1/17 [00:00<00:01,  9.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2357 ||: 100%|██████████| 17/17 [00:01<00:00,  9.86it/s]\n",
            "BLEU: 0.0034, loss: 0.2550 ||: 100%|██████████| 3/3 [00:00<00:00,  5.00it/s]\n",
            "loss: 0.2603 ||:   6%|▌         | 1/17 [00:00<00:01,  8.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2289 ||: 100%|██████████| 17/17 [00:01<00:00, 10.13it/s]\n",
            "BLEU: 0.0170, loss: 0.2460 ||: 100%|██████████| 3/3 [00:00<00:00,  5.54it/s]\n",
            "  0%|          | 0/17 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 26\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2259 ||: 100%|██████████| 17/17 [00:01<00:00,  9.45it/s]\n",
            "BLEU: 0.0023, loss: 0.2694 ||: 100%|██████████| 3/3 [00:00<00:00,  5.19it/s]\n",
            "  0%|          | 0/17 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2234 ||: 100%|██████████| 17/17 [00:01<00:00,  9.84it/s]\n",
            "BLEU: 0.0019, loss: 0.2337 ||: 100%|██████████| 3/3 [00:00<00:00,  4.72it/s]\n",
            "  0%|          | 0/17 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 28\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2191 ||: 100%|██████████| 17/17 [00:01<00:00, 10.25it/s]\n",
            "BLEU: 0.0023, loss: 0.2714 ||: 100%|██████████| 3/3 [00:00<00:00,  5.63it/s]\n",
            "  0%|          | 0/17 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2203 ||: 100%|██████████| 17/17 [00:01<00:00, 11.19it/s]\n",
            "BLEU: 0.0009, loss: 0.2318 ||: 100%|██████████| 3/3 [00:00<00:00,  6.10it/s]\n",
            "loss: 0.2616 ||:   6%|▌         | 1/17 [00:00<00:01,  9.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2197 ||: 100%|██████████| 17/17 [00:01<00:00, 11.49it/s]\n",
            "BLEU: 0.1318, loss: 0.2685 ||: 100%|██████████| 3/3 [00:00<00:00,  5.52it/s]\n",
            "loss: 0.2153 ||:   6%|▌         | 1/17 [00:00<00:01,  9.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 31\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2171 ||: 100%|██████████| 17/17 [00:01<00:00, 11.32it/s]\n",
            "BLEU: 0.0014, loss: 0.2551 ||: 100%|██████████| 3/3 [00:00<00:00,  5.42it/s]\n",
            "  0%|          | 0/17 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2182 ||: 100%|██████████| 17/17 [00:01<00:00, 11.11it/s]\n",
            "BLEU: 0.0360, loss: 0.2336 ||: 100%|██████████| 3/3 [00:00<00:00,  6.29it/s]\n",
            "loss: 0.1952 ||:   6%|▌         | 1/17 [00:00<00:01,  9.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 33\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2167 ||: 100%|██████████| 17/17 [00:01<00:00, 11.65it/s]\n",
            "BLEU: 0.0034, loss: 0.2259 ||: 100%|██████████| 3/3 [00:00<00:00,  6.04it/s]\n",
            "loss: 0.1402 ||:   6%|▌         | 1/17 [00:00<00:01,  9.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 34\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2149 ||: 100%|██████████| 17/17 [00:01<00:00, 11.36it/s]\n",
            "BLEU: 0.0532, loss: 0.2266 ||: 100%|██████████| 3/3 [00:00<00:00,  5.89it/s]\n",
            "  0%|          | 0/17 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 35\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2158 ||: 100%|██████████| 17/17 [00:01<00:00, 11.53it/s]\n",
            "BLEU: 0.0046, loss: 0.2677 ||: 100%|██████████| 3/3 [00:00<00:00,  5.94it/s]\n",
            "  0%|          | 0/17 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 36\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2132 ||: 100%|██████████| 17/17 [00:01<00:00, 11.50it/s]\n",
            "BLEU: 0.0040, loss: 0.2641 ||: 100%|██████████| 3/3 [00:00<00:00,  5.73it/s]\n",
            "loss: 0.2384 ||:   6%|▌         | 1/17 [00:00<00:01,  9.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 37\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2128 ||: 100%|██████████| 17/17 [00:01<00:00, 11.30it/s]\n",
            "BLEU: 0.0042, loss: 0.2695 ||: 100%|██████████| 3/3 [00:00<00:00,  5.73it/s]\n",
            "  0%|          | 0/17 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 38\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2124 ||: 100%|██████████| 17/17 [00:01<00:00, 11.32it/s]\n",
            "BLEU: 0.0886, loss: 0.2213 ||: 100%|██████████| 3/3 [00:00<00:00,  5.63it/s]\n",
            "  0%|          | 0/17 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 39\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2102 ||: 100%|██████████| 17/17 [00:01<00:00, 11.38it/s]\n",
            "BLEU: 0.0026, loss: 0.2705 ||: 100%|██████████| 3/3 [00:00<00:00,  5.75it/s]\n",
            "  0%|          | 0/17 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 40\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2085 ||: 100%|██████████| 17/17 [00:01<00:00, 12.07it/s]\n",
            "BLEU: 0.0010, loss: 0.2425 ||: 100%|██████████| 3/3 [00:00<00:00,  5.87it/s]\n",
            "loss: 0.1251 ||:   6%|▌         | 1/17 [00:00<00:01,  8.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 41\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2102 ||: 100%|██████████| 17/17 [00:01<00:00, 11.01it/s]\n",
            "BLEU: 0.0031, loss: 0.2428 ||: 100%|██████████| 3/3 [00:00<00:00,  5.62it/s]\n",
            "loss: 0.1935 ||:   6%|▌         | 1/17 [00:00<00:01,  9.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 42\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2129 ||: 100%|██████████| 17/17 [00:01<00:00, 11.38it/s]\n",
            "BLEU: 0.0041, loss: 0.2323 ||: 100%|██████████| 3/3 [00:00<00:00,  5.71it/s]\n",
            "loss: 0.1321 ||:   6%|▌         | 1/17 [00:00<00:01,  8.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 43\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2128 ||: 100%|██████████| 17/17 [00:01<00:00, 11.29it/s]\n",
            "BLEU: 0.0040, loss: 0.2636 ||: 100%|██████████| 3/3 [00:00<00:00,  6.17it/s]\n",
            "loss: 0.1603 ||:   6%|▌         | 1/17 [00:00<00:01,  9.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 44\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2097 ||: 100%|██████████| 17/17 [00:01<00:00, 11.32it/s]\n",
            "BLEU: 0.0040, loss: 0.2213 ||: 100%|██████████| 3/3 [00:00<00:00,  6.22it/s]\n",
            "loss: 0.1690 ||:   6%|▌         | 1/17 [00:00<00:01,  9.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 45\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2087 ||: 100%|██████████| 17/17 [00:01<00:00, 11.81it/s]\n",
            "BLEU: 0.0157, loss: 0.2251 ||: 100%|██████████| 3/3 [00:00<00:00,  5.87it/s]\n",
            "loss: 0.1361 ||:   6%|▌         | 1/17 [00:00<00:01,  8.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 46\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2102 ||: 100%|██████████| 17/17 [00:01<00:00, 11.17it/s]\n",
            "BLEU: 0.0022, loss: 0.2187 ||: 100%|██████████| 3/3 [00:00<00:00,  6.08it/s]\n",
            "loss: 0.2342 ||:   6%|▌         | 1/17 [00:00<00:01,  8.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 47\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2086 ||: 100%|██████████| 17/17 [00:01<00:00, 11.37it/s]\n",
            "BLEU: 0.0039, loss: 0.2219 ||: 100%|██████████| 3/3 [00:00<00:00,  5.66it/s]\n",
            "loss: 0.1646 ||:   6%|▌         | 1/17 [00:00<00:01,  8.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 48\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2059 ||: 100%|██████████| 17/17 [00:01<00:00, 11.28it/s]\n",
            "BLEU: 0.0156, loss: 0.2150 ||: 100%|██████████| 3/3 [00:00<00:00,  6.32it/s]\n",
            "loss: 0.1235 ||:   6%|▌         | 1/17 [00:00<00:01,  8.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 49\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2050 ||: 100%|██████████| 17/17 [00:01<00:00, 12.04it/s]\n",
            "BLEU: 0.0031, loss: 0.2201 ||: 100%|██████████| 3/3 [00:00<00:00,  5.57it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SOURCE: [@start@, Are, you, young, ?, @end@]\n",
            "GOLD: [@start@, A, g, e,  , d, o, e, s, n, ', t,  , r, e, a, l, l, y,  , a, p, p, l, y,  , t, o,  , m, e, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, What, do, you, want, to, know, about, me, ?, @end@]\n",
            "GOLD: [@start@, I, ', m,  , b, e, t, t, e, r,  , a, t,  , a, n, s, w, e, r, i, n, g,  , q, u, e, s, t, i, o, n, s, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, You, bore, me, @end@]\n",
            "GOLD: [@start@, I,  , a, i, m,  , f, o, r,  , e, f, f, i, c, i, e, n, c, y, ., @end@]\n",
            "PRED: ['I', ' ', 'a', 'p', 'o', 'l', 'o', 'g', 'i', 'z', 'e', '.']\n",
            "SOURCE: [@start@, Why, are, you, so, boring, ?, @end@]\n",
            "GOLD: [@start@, I,  , a, i, m,  , f, o, r,  , e, f, f, i, c, i, e, n, c, y, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, Cook, me, something, @end@]\n",
            "GOLD: [@start@, T, h, a, t, ', s,  , n, o, t,  , s, o, m, e, t, h, i, n, g,  , I,  , c, a, n,  , d, o, ., @end@]\n",
            "PRED: ['I', ' ', 'a', 'p', 'o', 'l', 'o', 'g', 'i', 'z', 'e', '.']\n",
            "SOURCE: [@start@, What, can, you, do, ?, @end@]\n",
            "GOLD: [@start@, I, ', m,  , h, e, r, e,  , t, o,  , a, n, s, w, e, r,  , y, o, u, r,  , q, u, e, s, t, i, o, n, s,  , a, n, d,  , h, e, l, p,  , o, u, t, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, Which, people, made, you, ?, @end@]\n",
            "GOLD: [@start@, P, e, o, p, l, e,  , c, r, e, a, t, e, d,  , m, e, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, Do, you, have, a, family, ?, @end@]\n",
            "GOLD: [@start@, I,  , d, o, n, ', t,  , h, a, v, e,  , f, a, m, i, l, y, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, Are, you, a, man, ?, @end@]\n",
            "GOLD: [@start@, T, h, a, t, ', s,  , a,  , b, i, o, l, o, g, i, c, a, l,  , c, o, n, c, e, p, t,  , t, h, a, t,  , d, o, e, s, n, ', t,  , a, p, p, l, y,  , t, o,  , m, e, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, What, 's, your, gender, ?, @end@]\n",
            "GOLD: [@start@, T, h, a, t, ', s,  , a,  , b, i, o, l, o, g, i, c, a, l,  , c, o, n, c, e, p, t,  , t, h, a, t,  , d, o, e, s, n, ', t,  , a, p, p, l, y,  , t, o,  , m, e, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PzqTqB_X9i3M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "a0c6e991-5e98-4b4e-c4ad-669398e6a3ea"
      },
      "cell_type": "code",
      "source": [
        "metrics"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'best_epoch': 48,\n",
              " 'best_validation_BLEU': 0.015575878016380471,\n",
              " 'best_validation_loss': 0.21502425273259482,\n",
              " 'epoch': 0,\n",
              " 'peak_cpu_memory_MB': 3659.132,\n",
              " 'peak_gpu_0_memory_MB': 1371,\n",
              " 'training_cpu_memory_MB': 3659.132,\n",
              " 'training_duration': '00:00:02',\n",
              " 'training_epochs': 0,\n",
              " 'training_gpu_0_memory_MB': 1371,\n",
              " 'training_loss': 0.20500567292465882,\n",
              " 'training_start_epoch': 0,\n",
              " 'validation_BLEU': 0.0030695841259323338,\n",
              " 'validation_loss': 0.2201482057571411}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "LEhirTqWQIKd",
        "colab_type": "code",
        "outputId": "19dd4ceb-038c-4510-91c0-1a78816cca0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2657
        }
      },
      "cell_type": "code",
      "source": [
        "for instance in itertools.islice(validation_dataset, 50):\n",
        "          print('SOURCE:', instance.fields['source_tokens'].tokens)\n",
        "          print('GOLD:', instance.fields['target_tokens'].tokens)\n",
        "          print('PRED:', predictor.predict_instance(instance)['predicted_tokens'])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SOURCE: [@start@, Are, you, young, ?, @end@]\n",
            "GOLD: [@start@, A, g, e,  , d, o, e, s, n, ', t,  , r, e, a, l, l, y,  , a, p, p, l, y,  , t, o,  , m, e, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, What, do, you, want, to, know, about, me, ?, @end@]\n",
            "GOLD: [@start@, I, ', m,  , b, e, t, t, e, r,  , a, t,  , a, n, s, w, e, r, i, n, g,  , q, u, e, s, t, i, o, n, s, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, You, bore, me, @end@]\n",
            "GOLD: [@start@, I,  , a, i, m,  , f, o, r,  , e, f, f, i, c, i, e, n, c, y, ., @end@]\n",
            "PRED: ['I', ' ', 'a', 'p', 'o', 'l', 'o', 'g', 'i', 'z', 'e', '.']\n",
            "SOURCE: [@start@, Why, are, you, so, boring, ?, @end@]\n",
            "GOLD: [@start@, I,  , a, i, m,  , f, o, r,  , e, f, f, i, c, i, e, n, c, y, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, Cook, me, something, @end@]\n",
            "GOLD: [@start@, T, h, a, t, ', s,  , n, o, t,  , s, o, m, e, t, h, i, n, g,  , I,  , c, a, n,  , d, o, ., @end@]\n",
            "PRED: ['I', ' ', 'a', 'p', 'o', 'l', 'o', 'g', 'i', 'z', 'e', '.']\n",
            "SOURCE: [@start@, What, can, you, do, ?, @end@]\n",
            "GOLD: [@start@, I, ', m,  , h, e, r, e,  , t, o,  , a, n, s, w, e, r,  , y, o, u, r,  , q, u, e, s, t, i, o, n, s,  , a, n, d,  , h, e, l, p,  , o, u, t, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, Which, people, made, you, ?, @end@]\n",
            "GOLD: [@start@, P, e, o, p, l, e,  , c, r, e, a, t, e, d,  , m, e, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, Do, you, have, a, family, ?, @end@]\n",
            "GOLD: [@start@, I,  , d, o, n, ', t,  , h, a, v, e,  , f, a, m, i, l, y, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, Are, you, a, man, ?, @end@]\n",
            "GOLD: [@start@, T, h, a, t, ', s,  , a,  , b, i, o, l, o, g, i, c, a, l,  , c, o, n, c, e, p, t,  , t, h, a, t,  , d, o, e, s, n, ', t,  , a, p, p, l, y,  , t, o,  , m, e, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, What, 's, your, gender, ?, @end@]\n",
            "GOLD: [@start@, T, h, a, t, ', s,  , a,  , b, i, o, l, o, g, i, c, a, l,  , c, o, n, c, e, p, t,  , t, h, a, t,  , d, o, e, s, n, ', t,  , a, p, p, l, y,  , t, o,  , m, e, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, Do, n't, you, get, hungry, ?, @end@]\n",
            "GOLD: [@start@, I,  , d, o, n, ', t,  , n, e, e, d,  , t, o,  , e, a, t, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, Do, you, know, Alexa, ?, @end@]\n",
            "GOLD: [@start@, I, ', v, e,  , h, e, a, r, d,  , o, f,  , o, t, h, e, r,  , b, o, t, s, ,,  , b, u, t,  , I,  , h, a, v, e, n, ', t,  , m, e, t,  , a, n, y, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, Do, you, know, other, digital, agents, ?, @end@]\n",
            "GOLD: [@start@, I, ', v, e,  , h, e, a, r, d,  , o, f,  , o, t, h, e, r,  , b, o, t, s, ,,  , b, u, t,  , I,  , h, a, v, e, n, ', t,  , m, e, t,  , a, n, y, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, Do, you, like, baseball, ?, @end@]\n",
            "GOLD: [@start@, I,  , d, o, n, ', t,  , r, e, a, l, l, y,  , h, a, v, e,  , a, n,  , o, p, i, n, i, o, n,  , a, b, o, u, t,  , t, h, a, t, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, What, do, you, think, about, bots, ?, @end@]\n",
            "GOLD: [@start@, I,  , c, o, u, l, d, n, ', t,  , s, p, e, a, k,  , t, o,  , t, h, a, t,  , w, i, t, h,  , a, n, y,  , a, u, t, h, o, r, i, t, y, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, What, 's, the, meaning, of, life, ?, @end@]\n",
            "GOLD: [@start@, I,  , d, o, n, ', t,  , k, n, o, w, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, What, should, I, do, ?, @end@]\n",
            "GOLD: [@start@, I,  , w, o, u, l, d, n, ', t,  , k, n, o, w,  , h, o, w,  , t, o,  , a, d, v, i, s, e,  , a, b, o, u, t,  , t, h, i, s, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, Are, you, smarter, than, me, ?, @end@]\n",
            "GOLD: [@start@, Y, o, u, ', r, e,  , d, e, f, i, n, i, t, e, l, y,  , s, m, a, r, t, e, r,  , t, h, a, n,  , I,  , a, m, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, Are, you, a, fan, of, Alexa, ?, @end@]\n",
            "GOLD: [@start@, W, e, ', r, e,  , a, l, l,  , h, e, r, e,  , t, o,  , h, e, l, p, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, Are, you, asexual, ?, @end@]\n",
            "GOLD: [@start@, I, ', m,  , d, i, g, i, t, a, l, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, You, 're, really, smart, @end@]\n",
            "GOLD: [@start@, I,  , d, o,  , w, h, a, t,  , I,  , c, a, n, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, Do, you, have, a, husband, ?, @end@]\n",
            "GOLD: [@start@, I, ', m,  , a, l, l,  , b, u, s, i, n, e, s, s, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, Can, you, chat, with, me, ?, @end@]\n",
            "GOLD: [@start@, I, ', m,  , a, l, w, a, y, s,  , h, a, p, p, y,  , t, o,  , c, h, a, t, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, Are, you, human, ?, @end@]\n",
            "GOLD: [@start@, I, ', m,  , d, i, g, i, t, a, l, .,  , I, n,  , o, t, h, e, r,  , w, o, r, d, s, ,,  , I, ', m,  , n, o, t,  , h, u, m, a, n, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, What, state, are, you, from, ?, @end@]\n",
            "GOLD: [@start@, I, ', m,  , d, i, g, i, t, a, l, .,  , I,  , d, o, n, ', t,  , h, a, v, e,  , a,  , p, h, y, s, i, c, a, l,  , l, o, c, a, t, i, o, n, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, What, are, you, doing, later, ?, @end@]\n",
            "GOLD: [@start@, T, h, i, s,  , i, s,  , w, h, a, t,  , I,  , d, o,  , e, v, e, r, y,  , d, a, y, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, You, ca, n't, work, for, me, anymore, @end@]\n",
            "GOLD: [@start@, O, k, a, y, ,,  , b, u, t,  , I, ', m,  , s, t, i, l, l,  , h, e, r, e,  , i, f,  , y, o, u,  , n, e, e, d,  , m, e, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, Say, a, joke, @end@]\n",
            "GOLD: [@start@, I, ', m,  , n, o, t,  , r, e, a, l, l, y,  , t, h, a, t,  , f, u, n, n, y, ., @end@]\n",
            "PRED: ['I', ' ', 'a', 'p', 'o', 'l', 'o', 'g', 'i', 'z', 'e', '.']\n",
            "SOURCE: [@start@, Give, me, another, joke, @end@]\n",
            "GOLD: [@start@, I,  , d, o, n, ', t,  , h, a, v, e,  , a, n, y,  , j, o, k, e, s,  , l, i, n, e, d,  , u, p, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, Shut, up, @end@]\n",
            "GOLD: [@start@, V, e, r, y,  , w, e, l, l, ., @end@]\n",
            "PRED: ['I', ' ', 'a', 'p', 'o', 'l', 'o', 'g', 'i', 'z', 'e', '.']\n",
            "SOURCE: [@start@, Sing, a, song, @end@]\n",
            "GOLD: [@start@, I, ', m,  , a, f, r, a, i, d,  , I, ', m,  , n, o, t,  , m, u, s, i, c, a, l, l, y,  , i, n, c, l, i, n, e, d, ., @end@]\n",
            "PRED: ['I', ' ', 'a', 'p', 'o', 'l', 'o', 'g', 'i', 'z', 'e', '.']\n",
            "SOURCE: [@start@, Sing, something, @end@]\n",
            "GOLD: [@start@, I, ', m,  , a, f, r, a, i, d,  , I, ', m,  , n, o, t,  , m, u, s, i, c, a, l, l, y,  , i, n, c, l, i, n, e, d, ., @end@]\n",
            "PRED: ['I', ' ', 'a', 'p', 'o', 'l', 'o', 'g', 'i', 'z', 'e', '.']\n",
            "SOURCE: [@start@, You, are, funny, :), @end@]\n",
            "GOLD: [@start@, I,  , a, i, m,  , t, o,  , s, e, r, v, e, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, You, 're, dumb, @end@]\n",
            "GOLD: [@start@, I,  , t, r, y, ,,  , b, u, t,  , I,  , d, o, n, ', t,  , a, l, w, a, y, s,  , g, e, t,  , i, t,  , r, i, g, h, t, ., @end@]\n",
            "PRED: ['I', ' ', 'a', 'p', 'o', 'l', 'o', 'g', 'i', 'z', 'e', '.']\n",
            "SOURCE: [@start@, You, 're, not, funny, @end@]\n",
            "GOLD: [@start@, S, o, m, e, t, i, m, e, s,  , h, u, m, o, r,  , i, s,  , t, r, i, c, k, y,  , f, o, r,  , a,  , b, o, t, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, You, 're, not, answering, my, question, @end@]\n",
            "GOLD: [@start@, S, o, r, r, y,  , a, b, o, u, t,  , t, h, a, t, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, FALSE, @end@]\n",
            "GOLD: [@start@, S, o, r, r, y,  , a, b, o, u, t,  , t, h, a, t, ., @end@]\n",
            "PRED: ['H', 'e', 'l', 'l', 'o', '.']\n",
            "SOURCE: [@start@, That, 's, awesome, @end@]\n",
            "GOLD: [@start@, T, h, a, t, ', s,  , g, r, e, a, t, ., @end@]\n",
            "PRED: ['I', ' ', 'a', 'p', 'o', 'l', 'o', 'g', 'i', 'z', 'e', '.']\n",
            "SOURCE: [@start@, Excuse, me, @end@]\n",
            "GOLD: [@start@, N, o,  , p, r, o, b, l, e, m, ., @end@]\n",
            "PRED: ['I', ' ', 'a', 'p', 'o', 'l', 'o', 'g', 'i', 'z', 'e', '.']\n",
            "SOURCE: [@start@, Why, do, you, think, that, ?, @end@]\n",
            "GOLD: [@start@, S, o, r, r, y, ,,  , I,  , d, o, n, ', t,  , u, n, d, e, r, s, t, a, n, d, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, Yes, ,, that, 's, right, @end@]\n",
            "GOLD: [@start@, E, x, c, e, l, l, e, n, t, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, Thank, you, @end@]\n",
            "GOLD: [@start@, Y, o, u, ', r, e,  , w, e, l, c, o, m, e, ., @end@]\n",
            "PRED: ['I', ' ', 'a', 'p', 'o', 'l', 'o', 'g', 'i', 'z', 'e', '.']\n",
            "SOURCE: [@start@, You, 're, not, making, sense, @end@]\n",
            "GOLD: [@start@, I,  , t, h, i, n, k,  , I,  , m, i, g, h, t,  , h, a, v, e,  , g, o, t, t, e, n,  , l, o, s, t,  , t, h, e, r, e, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, It, 's, my, pleasure, @end@]\n",
            "GOLD: [@start@, G, r, e, a, t, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, Hi, @end@]\n",
            "GOLD: [@start@, H, e, l, l, o, ., @end@]\n",
            "PRED: ['H', 'e', 'l', 'l', 'o', '.']\n",
            "SOURCE: [@start@, Night, @end@]\n",
            "GOLD: [@start@, G, o, o, d,  , n, i, g, h, t, ., @end@]\n",
            "PRED: ['H', 'e', 'l', 'l', 'o', '.']\n",
            "SOURCE: [@start@, How, 's, your, day, going, ?, @end@]\n",
            "GOLD: [@start@, G, o, o, d, ,,  , t, h, a, n, k, s, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, Hi, Google, @end@]\n",
            "GOLD: [@start@, T, h, a, t, ', s,  , n, o, t,  , m, e, ,,  , b, u, t,  , h, e, l, l, o, ., @end@]\n",
            "PRED: ['I', ' ', 'a', 'p', 'o', 'l', 'o', 'g', 'i', 'z', 'e', '.']\n",
            "SOURCE: [@start@, What, 's, up, ?, @end@]\n",
            "GOLD: [@start@, J, u, s, t,  , s, t, a, n, d, i, n, g,  , b, y, ,,  , r, e, a, d, y,  , t, o,  , h, e, l, p, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n",
            "SOURCE: [@start@, Give, me, a, high, five, @end@]\n",
            "GOLD: [@start@, S, o, r, r, y, ,,  , I,  , c, a, n, ', t,  , d, o,  , t, h, a, t, ., @end@]\n",
            "PRED: ['O', 'k', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}